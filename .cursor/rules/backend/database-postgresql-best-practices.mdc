---
description: PostgreSQL optimization with SQLAlchemy 2.0 and async patterns
globs: **/*models*.py, **/database*.py, **/migrations/**/*.py, alembic/**/*.py
alwaysApply: false
---

---
description: "PostgreSQL optimization with SQLAlchemy 2.0 and async patterns"
globs: ["**/models/**/*.py", "**/database.py", "**/migrations/**/*.py", "**/alembic/**/*.py", "alembic.ini"]
alwaysApply: false
---

# PostgreSQL & Database Best Practices

–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å PostgreSQL, SQLAlchemy 2.0 –∏ –º–∏–≥—Ä–∞—Ü–∏—è–º–∏ –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.

## Database Design Principles üóÑÔ∏è

### 1. Table Structure & Naming
```sql
-- –ò—Å–ø–æ–ª—å–∑—É–π snake_case –¥–ª—è —Ç–∞–±–ª–∏—Ü –∏ –∫–æ–ª–æ–Ω–æ–∫
CREATE TABLE user_profiles (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    full_name VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö –∫–ª—é—á–µ–π
CREATE INDEX idx_user_profiles_user_id ON user_profiles(user_id);
CREATE INDEX idx_user_profiles_created_at ON user_profiles(created_at);
```

### 2. Primary Keys & UUIDs
```sql
-- –ê–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω—ã–µ ID –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ç–∞–±–ª–∏—Ü
CREATE TABLE comments (
    id SERIAL PRIMARY KEY,
    vk_comment_id BIGINT UNIQUE NOT NULL,  -- External ID from VK
    content TEXT NOT NULL
);

-- UUID –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö API
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE TABLE public_documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

### 3. Data Types & Constraints
```sql
-- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
CREATE TABLE vk_groups (
    id SERIAL PRIMARY KEY,
    vk_group_id BIGINT UNIQUE NOT NULL,           -- VK ID –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–∏–º
    name VARCHAR(255) NOT NULL CHECK (length(name) > 0),
    screen_name VARCHAR(100) UNIQUE,
    description TEXT,
    is_active BOOLEAN DEFAULT true NOT NULL,
    member_count INTEGER CHECK (member_count >= 0),
    last_check TIMESTAMP WITH TIME ZONE,
    check_interval INTEGER DEFAULT 300 CHECK (check_interval > 0),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL
);
```

## SQLAlchemy 2.0 Models üîó

### 4. Modern Model Definition
```python
# models/base.py
from datetime import datetime
from sqlalchemy import DateTime, func, MetaData
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column

# Unified naming convention
metadata = MetaData(naming_convention={
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s"
})

class Base(DeclarativeBase):
    metadata = metadata

class TimestampMixin:
    """Mixin –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö timestamp –ø–æ–ª–µ–π."""
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False
    )
```

### 5. Complex Model with Relations
```python
# models/group.py
from sqlalchemy import String, BigInteger, Boolean, Integer, Text, Index
from sqlalchemy.orm import Mapped, mapped_column, relationship
from typing import List, Optional

class VkGroup(Base, TimestampMixin):
    __tablename__ = "vk_groups"
    
    id: Mapped[int] = mapped_column(primary_key=True)
    vk_group_id: Mapped[int] = mapped_column(BigInteger, unique=True, nullable=False)
    name: Mapped[str] = mapped_column(String(255), nullable=False)
    screen_name: Mapped[Optional[str]] = mapped_column(String(100), unique=True)
    description: Mapped[Optional[str]] = mapped_column(Text)
    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
    member_count: Mapped[Optional[int]] = mapped_column(Integer)
    last_check: Mapped[Optional[datetime]] = mapped_column(DateTime(timezone=True))
    check_interval: Mapped[int] = mapped_column(Integer, default=300, nullable=False)
    
    # Relationships
    comments: Mapped[List["Comment"]] = relationship(
        back_populates="group",
        cascade="all, delete-orphan",
        passive_deletes=True
    )
    scan_logs: Mapped[List["ScanLog"]] = relationship(
        back_populates="group",
        cascade="all, delete-orphan"
    )
    
    # Composite indexes
    __table_args__ = (
        Index('ix_vk_groups_active_check', 'is_active', 'last_check'),
        Index('ix_vk_groups_screen_name_active', 'screen_name', 'is_active'),
    )
    
    def __repr__(self) -> str:
        return f"<VkGroup(id={self.id}, name='{self.name}', vk_id={self.vk_group_id})>"
```

### 6. Many-to-Many Relations
```python
# models/associations.py
from sqlalchemy import Table, ForeignKey
from sqlalchemy.orm import Mapped, mapped_column

# Association table for groups and keywords
group_keyword_association = Table(
    "group_keywords",
    Base.metadata,
    mapped_column("group_id", ForeignKey("vk_groups.id", ondelete="CASCADE"), primary_key=True),
    mapped_column("keyword_id", ForeignKey("keywords.id", ondelete="CASCADE"), primary_key=True),
    Index('ix_group_keywords_group_id', 'group_id'),
    Index('ix_group_keywords_keyword_id', 'keyword_id')
)

# In models
class VkGroup(Base, TimestampMixin):
    # ... other fields
    keywords: Mapped[List["Keyword"]] = relationship(
        secondary=group_keyword_association,
        back_populates="groups"
    )

class Keyword(Base, TimestampMixin):
    # ... other fields
    groups: Mapped[List["VkGroup"]] = relationship(
        secondary=group_keyword_association,
        back_populates="keywords"
    )
```

## Database Connection & Sessions üîå

### 7. Async Connection Setup
```python
# database.py
from sqlalchemy.ext.asyncio import (
    AsyncSession,
    create_async_engine,
    async_sessionmaker,
    AsyncEngine
)
from sqlalchemy.pool import NullPool
from app.config import settings

class DatabaseManager:
    def __init__(self):
        self.engine: Optional[AsyncEngine] = None
        self.session_maker: Optional[async_sessionmaker] = None
    
    def init_db(self) -> None:
        self.engine = create_async_engine(
            settings.DATABASE_URL,
            echo=settings.DATABASE_ECHO,
            echo_pool=settings.DEBUG,
            pool_size=20,
            max_overflow=30,
            pool_recycle=3600,
            pool_pre_ping=True,
            # –î–ª—è —Ç–µ—Å—Ç–æ–≤
            poolclass=NullPool if settings.ENVIRONMENT == "test" else None,
        )
        
        self.session_maker = async_sessionmaker(
            bind=self.engine,
            class_=AsyncSession,
            expire_on_commit=False,
            autoflush=True,
            autocommit=False,
        )
    
    async def close_db(self) -> None:
        if self.engine:
            await self.engine.dispose()

# Global instance
db_manager = DatabaseManager()

# Dependency for FastAPI
async def get_db() -> AsyncSession:
    if not db_manager.session_maker:
        raise RuntimeError("Database not initialized")
    
    async with db_manager.session_maker() as session:
        try:
            yield session
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()
```

### 8. Connection Health Checks
```python
# database/health.py
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

async def check_database_health(session: AsyncSession) -> dict:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    try:
        # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
        result = await session.execute(text("SELECT 1"))
        result.scalar()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ PostgreSQL
        version_result = await session.execute(text("SELECT version()"))
        version = version_result.scalar()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        connections_result = await session.execute(text("""
            SELECT count(*) as active_connections 
            FROM pg_stat_activity 
            WHERE state = 'active'
        """))
        active_connections = connections_result.scalar()
        
        return {
            "status": "healthy",
            "version": version,
            "active_connections": active_connections
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
```

## Query Optimization üöÄ

### 9. Efficient Queries with Relations
```python
# services/group_service.py
from sqlalchemy import select, and_, or_, func, desc
from sqlalchemy.orm import selectinload, joinedload, contains_eager

class GroupService:
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def get_active_groups_with_stats(self) -> List[VkGroup]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
        query = (
            select(VkGroup)
            .options(
                selectinload(VkGroup.comments).options(
                    selectinload(Comment.keyword)
                )
            )
            .where(VkGroup.is_active == True)
            .order_by(desc(VkGroup.last_check))
        )
        result = await self.session.execute(query)
        return result.scalars().unique().all()
    
    async def get_groups_with_comment_count(self) -> List[tuple]:
        """–ì—Ä—É–ø–ø—ã —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
        query = (
            select(
                VkGroup.id,
                VkGroup.name,
                func.count(Comment.id).label('comment_count')
            )
            .outerjoin(Comment)
            .group_by(VkGroup.id, VkGroup.name)
            .having(func.count(Comment.id) > 0)
            .order_by(desc('comment_count'))
        )
        result = await self.session.execute(query)
        return result.all()
    
    async def search_groups(self, search_term: str, limit: int = 50) -> List[VkGroup]:
        """–ü–æ–∏—Å–∫ –≥—Ä—É–ø–ø –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ screen_name."""
        search = f"%{search_term}%"
        query = (
            select(VkGroup)
            .where(
                or_(
                    VkGroup.name.ilike(search),
                    VkGroup.screen_name.ilike(search)
                )
            )
            .limit(limit)
        )
        result = await self.session.execute(query)
        return result.scalars().all()
```

### 10. Batch Operations
```python
# services/comment_service.py
from sqlalchemy.dialects.postgresql import insert

class CommentService:
    async def bulk_create_comments(self, comments_data: List[dict]) -> List[Comment]:
        """–ú–∞—Å—Å–æ–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."""
        stmt = insert(Comment).values(comments_data)
        
        # PostgreSQL ON CONFLICT –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        stmt = stmt.on_conflict_do_nothing(
            index_elements=['vk_comment_id', 'vk_post_id']
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        stmt = stmt.returning(Comment.id)
        
        result = await self.session.execute(stmt)
        await self.session.commit()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        created_ids = result.scalars().all()
        if created_ids:
            query = select(Comment).where(Comment.id.in_(created_ids))
            result = await self.session.execute(query)
            return result.scalars().all()
        return []
    
    async def bulk_update_sentiment(self, updates: List[dict]) -> None:
        """–ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ sentiment –¥–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
        await self.session.execute(
            update(Comment),
            updates
        )
        await self.session.commit()
```

## Alembic Migrations üì¶

### 11. Migration Configuration
```python
# alembic/env.py
import asyncio
from logging.config import fileConfig
from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import create_async_engine
from alembic import context

from app.config import settings
from app.models import Base  # Import all models

config = context.config

# Set database URL from settings
config.set_main_option("sqlalchemy.url", settings.DATABASE_URL.replace("+asyncpg", ""))

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = Base.metadata

def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        render_as_batch=True,
    )

    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection: Connection) -> None:
    context.configure(
        connection=connection, 
        target_metadata=target_metadata,
        render_as_batch=True,
    )

    with context.begin_transaction():
        context.run_migrations()

async def run_async_migrations() -> None:
    """Run migrations in 'online' mode with async engine."""
    connectable = create_async_engine(
        settings.DATABASE_URL,
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()

def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    asyncio.run(run_async_migrations())

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

### 12. Complex Migration Example
```python
# alembic/versions/001_create_vk_monitoring_tables.py
"""Create VK monitoring tables

Revision ID: 001
Revises: 
Create Date: 2024-01-01 12:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade() -> None:
    # Create groups table
    op.create_table(
        'vk_groups',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('vk_group_id', sa.BigInteger(), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('screen_name', sa.String(length=100), nullable=True),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('is_active', sa.Boolean(), nullable=False, server_default='true'),
        sa.Column('member_count', sa.Integer(), nullable=True),
        sa.Column('last_check', sa.DateTime(timezone=True), nullable=True),
        sa.Column('check_interval', sa.Integer(), nullable=False, server_default='300'),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('vk_group_id'),
        sa.UniqueConstraint('screen_name'),
        sa.CheckConstraint('member_count >= 0', name='ck_vk_groups_member_count_positive'),
        sa.CheckConstraint('check_interval > 0', name='ck_vk_groups_check_interval_positive'),
        sa.CheckConstraint("name != ''", name='ck_vk_groups_name_not_empty')
    )
    
    # Create indexes
    op.create_index('ix_vk_groups_active_check', 'vk_groups', ['is_active', 'last_check'])
    op.create_index('ix_vk_groups_screen_name_active', 'vk_groups', ['screen_name', 'is_active'])
    op.create_index('ix_vk_groups_created_at', 'vk_groups', ['created_at'])
    
    # Create keywords table
    op.create_table(
        'keywords',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('keyword', sa.String(length=255), nullable=False),
        sa.Column('category', sa.String(length=100), nullable=True),
        sa.Column('is_active', sa.Boolean(), nullable=False, server_default='true'),
        sa.Column('case_sensitive', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('whole_word', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.PrimaryKeyConstraint('id'),
        sa.CheckConstraint("keyword != ''", name='ck_keywords_keyword_not_empty')
    )
    
    op.create_index('ix_keywords_keyword', 'keywords', ['keyword'])
    op.create_index('ix_keywords_category_active', 'keywords', ['category', 'is_active'])
    
    # Create comments table
    op.create_table(
        'comments',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('vk_comment_id', sa.BigInteger(), nullable=False),
        sa.Column('vk_post_id', sa.BigInteger(), nullable=False),
        sa.Column('group_id', sa.Integer(), nullable=False),
        sa.Column('keyword_id', sa.Integer(), nullable=True),
        sa.Column('author_id', sa.BigInteger(), nullable=False),
        sa.Column('author_name', sa.String(length=255), nullable=True),
        sa.Column('author_screen_name', sa.String(length=100), nullable=True),
        sa.Column('text', sa.Text(), nullable=False),
        sa.Column('date', sa.DateTime(timezone=True), nullable=False),
        sa.Column('post_url', sa.String(length=500), nullable=True),
        sa.Column('comment_url', sa.String(length=500), nullable=True),
        sa.Column('is_reviewed', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('sentiment', sa.String(length=20), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.ForeignKeyConstraint(['group_id'], ['vk_groups.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['keyword_id'], ['keywords.id'], ondelete='SET NULL'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('vk_comment_id', 'vk_post_id', name='uq_comments_vk_comment_post'),
        sa.CheckConstraint("text != ''", name='ck_comments_text_not_empty')
    )
    
    # Indexes for performance
    op.create_index('ix_comments_group_id', 'comments', ['group_id'])
    op.create_index('ix_comments_keyword_id', 'comments', ['keyword_id'])
    op.create_index('ix_comments_date', 'comments', ['date'])
    op.create_index('ix_comments_author_id', 'comments', ['author_id'])
    op.create_index('ix_comments_sentiment_reviewed', 'comments', ['sentiment', 'is_reviewed'])

def downgrade() -> None:
    op.drop_table('comments')
    op.drop_table('keywords')
    op.drop_table('vk_groups')
```

## Performance Optimization üìà

### 13. Indexing Strategies
```sql
-- Composite indexes for common queries
CREATE INDEX CONCURRENTLY ix_comments_group_date_sentiment 
ON comments(group_id, date DESC, sentiment) 
WHERE is_reviewed = false;

-- Partial indexes
CREATE INDEX CONCURRENTLY ix_vk_groups_active_last_check
ON vk_groups(last_check DESC)
WHERE is_active = true;

-- Text search indexes
CREATE INDEX CONCURRENTLY ix_comments_text_gin
ON comments USING gin(to_tsvector('russian', text));

-- Functional indexes
CREATE INDEX CONCURRENTLY ix_comments_date_hour
ON comments(date_trunc('hour', date));
```

### 14. Query Performance Monitoring
```python
# utils/db_profiler.py
import time
import logging
from sqlalchemy import event
from sqlalchemy.engine import Engine

logger = logging.getLogger(__name__)

@event.listens_for(Engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    context._query_start_time = time.time()

@event.listens_for(Engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - context._query_start_time
    
    # Log slow queries
    if total > 0.5:  # 500ms threshold
        logger.warning(
            f"Slow query: {total:.3f}s\n"
            f"Statement: {statement}\n"
            f"Parameters: {parameters}"
        )

# Database statistics
async def get_database_stats(session: AsyncSession) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
    stats_query = text("""
        SELECT 
            schemaname,
            tablename,
            n_tup_ins as inserts,
            n_tup_upd as updates,
            n_tup_del as deletes,
            n_live_tup as live_tuples,
            n_dead_tup as dead_tuples
        FROM pg_stat_user_tables
        ORDER BY n_live_tup DESC;
    """)
    
    result = await session.execute(stats_query)
    return [dict(row) for row in result]
```

## Connection Pooling & Scaling üîß

### 15. Advanced Connection Pool
```python
# database/pool.py
from sqlalchemy.pool import QueuePool
from sqlalchemy.ext.asyncio import create_async_engine

def create_engine_with_custom_pool():
    return create_async_engine(
        settings.DATABASE_URL,
        poolclass=QueuePool,
        pool_size=20,              # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–∑–º–µ—Ä –ø—É–ª–∞
        max_overflow=30,           # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        pool_timeout=30,           # Timeout –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        pool_recycle=3600,         # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∫–∞–∂–¥—ã–π —á–∞—Å
        pool_pre_ping=True,        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        echo=settings.DATABASE_ECHO,
        echo_pool=settings.DEBUG,
        connect_args={
            "server_settings": {
                "application_name": "vk_monitor",
                "statement_timeout": "300000",  # 5 minutes
            }
        }
    )
```

### 16. Read/Write Split
```python
# database/multiple_dbs.py
from enum import Enum

class DatabaseType(Enum):
    READ = "read"
    WRITE = "write"

class DatabaseRouter:
    def __init__(self):
        self.write_engine = create_async_engine(settings.DATABASE_WRITE_URL)
        self.read_engine = create_async_engine(settings.DATABASE_READ_URL)
        
        self.write_session_maker = async_sessionmaker(bind=self.write_engine)
        self.read_session_maker = async_sessionmaker(bind=self.read_engine)
    
    def get_session_maker(self, db_type: DatabaseType):
        if db_type == DatabaseType.WRITE:
            return self.write_session_maker
        return self.read_session_maker

# Usage in services
class GroupService:
    async def get_groups(self) -> List[VkGroup]:
        # Read from replica
        async with router.get_session_maker(DatabaseType.READ)() as session:
            result = await session.execute(select(VkGroup))
            return result.scalars().all()
    
    async def create_group(self, group_data: dict) -> VkGroup:
        # Write to master
        async with router.get_session_maker(DatabaseType.WRITE)() as session:
            group = VkGroup(**group_data)
            session.add(group)
            await session.commit()
            return group
```

## Error Handling & Transactions üö®

### 17. Transaction Management
```python
# utils/transaction.py
from contextlib import asynccontextmanager
from sqlalchemy.ext.asyncio import AsyncSession

@asynccontextmanager
async def atomic_transaction(session: AsyncSession):
    """Context manager –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π."""
    try:
        await session.begin()
        yield session
        await session.commit()
    except Exception:
        await session.rollback()
        raise

# Usage
async def complex_operation(session: AsyncSession):
    async with atomic_transaction(session):
        # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—É
        group = VkGroup(name="Test Group", vk_group_id=12345)
        session.add(group)
        await session.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –±–µ–∑ –∫–æ–º–º–∏—Ç–∞
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        comment = Comment(group_id=group.id, text="Test comment")
        session.add(comment)
        
        # –ï—Å–ª–∏ –∑–¥–µ—Å—å –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –æ—à–∏–±–∫–∞, –≤—Å–µ –æ—Ç–∫–∞—Ç–∏—Ç—Å—è
        if some_condition:
            raise ValueError("Something went wrong")
```

### 18. Database Error Handling
```python
# exceptions/database.py
from sqlalchemy.exc import (
    IntegrityError, 
    DataError,
    OperationalError,
    InvalidRequestError
)
from fastapi import HTTPException

class DatabaseExceptionHandler:
    @staticmethod
    def handle_integrity_error(error: IntegrityError):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö."""
        error_msg = str(error.orig)
        
        if "unique constraint" in error_msg.lower():
            if "vk_group_id" in error_msg:
                raise HTTPException(
                    status_code=409,
                    detail="Group with this VK ID already exists"
                )
            elif "screen_name" in error_msg:
                raise HTTPException(
                    status_code=409,
                    detail="Group with this screen name already exists"
                )
        
        if "foreign key constraint" in error_msg.lower():
            raise HTTPException(
                status_code=400,
                detail="Referenced entity does not exist"
            )
        
        raise HTTPException(
            status_code=400,
            detail="Database constraint violation"
        )
    
    @staticmethod
    def handle_operational_error(error: OperationalError):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫."""
        error_msg = str(error.orig)
        
        if "timeout" in error_msg.lower():
            raise HTTPException(
                status_code=504,
                detail="Database operation timeout"
            )
        
        if "connection" in error_msg.lower():
            raise HTTPException(
                status_code=503,
                detail="Database connection error"
            )
        
        raise HTTPException(
            status_code=500,
            detail="Database operational error"
        )
```

## Database Maintenance üîß

### 19. Maintenance Scripts
```python
# scripts/db_maintenance.py
import asyncio
from sqlalchemy import text
from app.database import get_db

async def analyze_tables():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞."""
    async for session in get_db():
        await session.execute(text("ANALYZE;"))
        await session.commit()
        print("Database statistics updated")

async def vacuum_tables():
    """–û—á–∏—Å—Ç–∫–∞ –º–µ—Ä—Ç–≤—ã—Ö —Å—Ç—Ä–æ–∫."""
    async for session in get_db():
        # VACUUM –Ω–µ–ª—å–∑—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        await session.commit()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü
        result = await session.execute(text("""
            SELECT tablename FROM pg_tables 
            WHERE schemaname = 'public'
        """))
        tables = result.scalars().all()
        
        for table in tables:
            await session.execute(text(f"VACUUM ANALYZE {table};"))
        
        print(f"Vacuumed {len(tables)} tables")

async def reindex_tables():
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤."""
    async for session in get_db():
        await session.execute(text("REINDEX DATABASE vk_monitor;"))
        print("Database reindexed")

if __name__ == "__main__":
    asyncio.run(analyze_tables())
```

### 20. Monitoring Queries
```sql
-- –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    stddev_time
FROM pg_stat_statements 
WHERE mean_time > 100  -- –±–æ–ª–µ–µ 100ms
ORDER BY mean_time DESC
LIMIT 10;

-- –†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE idx_scan = 0
ORDER BY schemaname, tablename;
```

## Development Checklist ‚úÖ

### Schema Design:
- [ ] –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
- [ ] NOT NULL constraints –≥–¥–µ –Ω—É–∂–Ω–æ
- [ ] Check constraints –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- [ ] –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ foreign keys —Å ON DELETE
- [ ] –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- [ ] Indexes –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

### SQLAlchemy Models:
- [ ] Type hints –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π
- [ ] Relationships –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] Cascade options —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
- [ ] Proper naming conventions
- [ ] TimestampMixin –¥–ª—è –∞—É–¥–∏—Ç–∞

### Performance:
- [ ] Composite indexes –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- [ ] Partial indexes –≥–¥–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ
- [ ] Query optimization —Å EXPLAIN
- [ ] Connection pooling –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] N+1 queries –∏–∑–±–µ–≥–∞—é—Ç—Å—è

### Migrations:
- [ ] Alembic –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
- [ ] –ú–∏–≥—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä—É—é—Ç—Å—è
- [ ] Rollback –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
- [ ] Data migrations –æ—Ç–¥–µ–ª–µ–Ω—ã –æ—Ç schema

### Monitoring:
- [ ] Slow query logging
- [ ] Connection pool monitoring
- [ ] Database health checks
- [ ] Performance metrics
